== The Mechanics of Execution - An Overview of Code Generation

This is an extended tutorial on how to generate backend code from
intermediate code.   Don't start this until instructed. At
the very least, you should have intermediate code generation
working in your compiler first.

With that out of the way, this document introduces
introduces the basic mechanics of writing an interpreter, a
transpiler, and generation of machine code using LLVM and WebAssembly.
In general, none of this is "hard" except that there often a lot of
fiddly bits concerning tooling and data formats.  Some simplifications
have been made to make encoding easier (at the expense of a bit of
space optimization). 

For this tutorial, we're going to consider the following code fragment:

----
var x int = 4;
var y int = 5;
var d int = x * x + y * y;
print d;
----

When compiled by your compiler, you should generate the following 
intermediate code:

----
code = [
   ('GLOBALI', 'x'),
   ('CONSTI', 4),
   ('STORE', 'x'),
   ('GLOBALI', 'y'),
   ('CONSTI', 5),
   ('STORE', 'y'),
   ('GLOBALI', 'd'),
   ('LOAD', 'x'),
   ('LOAD', 'x'),
   ('MULI',),
   ('LOAD', 'y'),
   ('LOAD', 'y'),
   ('MULI',),
   ('ADDI',),
   ('STORE', 'd'),
   ('LOAD', 'd'),
   ('PRINTI',)
]
----

Copy the above `code` variable to a Python file where you can use it 
in some examples. 

=== Part (a) - Writing an Interpreter

One possible target for your compiler is to write an interpreter.  An
interpreter directly runs the instructions on a kind of simulated
machine. The simulated machine has memory, a stack, and a program
counter just like a real CPU.  Define the following class and try it
with the above code:

----
class Interpreter:
    def __init__(self):
        self.store = { }
        self.stack = [ ]
        self.pc = 0

    def run(self, code):
        self.pc = 0
        while self.pc < len(code):
            op, *opargs = code[self.pc]
            getattr(self, f'run_{op}')(*opargs)
            self.pc += 1

    def push(self, item):
        self.stack.append(item)

    def pop(self):
        return self.stack.pop()

    def run_GLOBALI(self, name):
        self.store[name] = None

    def run_CONSTI(self, value):
        self.push(value)

    def run_STORE(self, name):
        self.store[name] = self.pop()

    def run_LOAD(self, name):
        self.push(self.store[name])

    def run_ADDI(self):
        self.push(self.pop() + self.pop())

    def run_MULI(self):
        self.push(self.pop() * self.pop())

    def run_PRINTI(self):
        print(self.pop())

# Run it!
interp = Interpreter()
interp.run(code)
----

Modify your interpreter by giving it a new instruction `SUBI` and
running it on this program which should produce an output of "1":

----
code = [
    ('CONSTI', 5),
    ('CONSTI', 4),
    ('SUBI',)
    ('PRINTI',)
]
----

Direct interpretation of simulated instructions on a simulated machine
is how various scripting languages such as Python, Ruby, PHP, and so
forth work.  This "simulation" is a big part of dynamic typing.  It's
also why these languages run slower than compiled languages
like C.

=== Part (b) - Writing a Transpiler

Instead of directly running intermediate code, another option is to
turn the code into source code for another programming language such
as Python or C.  This is how early versions of C++ worked. It's also
the basis of modern languages such as TypeScript (transpiled to JavaScript).
A common target of transpiling is C.   Here is a transpiler that produces
Python:

----
class Transpiler:
    def __init__(self):
        self.outcode = 'def main():\n'
        self.stack = [ ]

    def translate(self, code):
        for op, *opargs in code:
            getattr(self, f'translate_{op}')(*opargs)
        self.outcode += '\nmain()\n'
        return self.outcode

    def push(self, item):
        self.stack.append(item)

    def pop(self):
        return self.stack.pop()

    def translate_GLOBALI(self, name):
        pass

    def translate_CONSTI(self, value):
        self.push(repr(value))

    def translate_STORE(self, name):
        self.outcode += f'    {name} = {self.pop()}\n'

    def translate_LOAD(self, name):
        self.push(name)

    def translate_ADDI(self):
        self.push(f'({self.pop()} + {self.pop()})')

    def translate_MULI(self):
        self.push(f'({self.pop()} * {self.pop()})')

    def translate_PRINTI(self):
        self.outcode += f'    print({self.pop()})\n'

trans = Transpiler()
print(trans.translate(code))
----

In this implementation, you still maintain an internal stack to manage
the construction of expressions (e.g., certain methods still push and pop
things from the stack).  However, instead of actually performing an
operation as with the interpreter, you're now producing source code to 
perform the operation.

If you run the program, you should get this:

----
bash % python3 transpile.py
def main():
    x = 4
    y = 5
    d = ((y * y) + (x * x))
    print(d)

main()
bash %
----

Try redirecting the output to a file and running it:

----
bash % python3 transpile.py > out.py
bash % python3 out.py
41
bash %
----

See if you can modify the program so that it produces C instead, creating the following
output code:

----
#include <stdio.h>
int main() {
    int x;
    int y;
    int d;
    x = 4;
    y = 5;
    d = ((y * y) + (x * x));
    printf("%i\n", (d));
}
----

If you're making a new language, transpiling is often a easy approach for getting
things to work.  Take your language, transpile it to C, combine with a few
library functions and you're running. 

=== Part (c) - Generating Assembly Code with LLVM

With transpiling, you're taking a high-level language and producing
output in a different high-level language.  Instead of that, you could
compile down to a low-level machine language that is either the actual
hardware or a very close approximation to it.  One such tool for doing
that is LLVM.  LLVM is used in a number of major projects such as the
clang C/C++ compiler.  It's also used to implement various so-called
JIT (Just in Time) compilation features.

LLVM is an extremely large project that can be daunting to jump into.
However, using it in a simple manner is not so bad. To explore the
basics, we're going to use the `llvmlite` package.  This is available
in the Anaconda Python distribution so if you're using that, you
should already have it.

==== LLVM Preliminaries

Your first task is to make sure Anaconda Python and the clang C/C++
compiler have been installed on your machine. Please review the README
file for the compilers project regarding installation notes.

==== Hello World

The first step in using LLVM is to make a LLVM module which contains
all of the code you will be generating.  Create a file
`hellollvm.py` and put this code into it:

----
# hellollvm.py
from llvmlite.ir import Module

mod = Module('hello')
print(mod)
----

Run the program and you should get some output like this:

----
bash % python3 hellollvm.py
; ModuleID = "hello"
target triple = "unknown-unknown-unknown"
target datalayout = ""

bash %
----

The output you're seeing is LLVM low-level code--a kind of architecture
independent assembly language. At this point, it's not too
interesting.  However, let's declare a function to put in the module.
Change the program to the following to declare a function with the C
prototype `int hello()`:

----
# hellollvm.py

from llvmlite.ir import (
    Module, Function, FunctionType, IntType
    )

mod = Module('hello')
int_type = IntType(32)
hello_func = Function(mod, FunctionType(int_type, []), name='hello')
print(mod)
----

Running the program, you should now get the following:

----
bash % python3 hellollvm.py
; ModuleID = "hello"
target triple = "unknown-unknown-unknown"
target datalayout = ""

declare i32 @"hello"() 

bash %
----

Again, it's not too interesting yet.  However, you can see
how a function declaration was placed in the module output. The LLVM
statement `declare i32 @"hello"()` is declaring a function that
returns a 32-bit integer and takes no arguments.

Let's add some code to the function.  To do this, you first need to
create a basic block. A basic block is a container that holds
low-level instructions.  Add the following to the program:

----
# hellollvm.py

from llvmlite.ir import (
    Module, Function, FunctionType, IntType, IRBuilder
    )

mod = Module('hello')
int_type = IntType(32)
hello_func = Function(mod, FunctionType(int_type, []), name='hello')
block = hello_func.append_basic_block('entry')
builder = IRBuilder(block)
builder.ret(Constant(IntType(32), 37))
print(mod)
----

Running the program should now produce this:

----
; ModuleID = "hello"
target triple = "unknown-unknown-unknown"
target datalayout = ""
    
define i32 @"hello"() 
{
entry:
  ret i32 37
}
----

There you are---a complete LLVM function that does nothing but return
the value 37. Now, a question arises: How do you go about getting it to run?

==== Compilation to a Standalone Executable

If you want to run your LLVM generated code, one approach is to feed it
to a LLVM-based compiler such as `clang`.  Save your generated
code to a file `hello.ll`:

----
bash % python3 hellollvm.py > hello.ll
bash % 
----

Now, write a short C program to bootstrap the function:

----
/* main.c */
#include <stdio.h>

extern int hello(); 

int main() {
    printf("hello() returned %i\n", hello());
}
----

Compile this program together with `hello.ll` to make an executable:

----
bash % clang main.c hello.ll
bash % ./a.out
hello() returned 37
bash %
----

This basic technique for invoking your code and creating stand-alone
programs will be useful for testing and development.  You also get the
advantage of being able to use C library functions such as
`printf()`.  Without this, you'd have to figure out how to perform
I/O directly using low-level LLVM instructions--which would not be
fun.

==== Just in Time Compilation

In our example, we are creating LLVM instructions, writing them to a
file, and using the `clang` compiler to produce an executable. 
It's possible that this won't work due to the local setup on
your machine (maybe you don't have clang installed correctly).
One feature of LLVM is that it can compile it's own code to executable
machine instructions without ever going to a file or using clang.  
You can do this entirely in Python and have Python call the resulting
function.

This part is rather tricky and obscure, but add the following code to
`hellollvm.py`:

----
# hellollvm.py 

... keep earlier LLVM example here ...

def run_jit(module):
    import llvmlite.binding as llvm

    llvm.initialize()
    llvm.initialize_native_target()
    llvm.initialize_native_asmprinter()

    target = llvm.Target.from_default_triple()
    target_machine = target.create_target_machine()
    compiled_mod = llvm.parse_assembly(str(module))
    engine = llvm.create_mcjit_compiler(compiled_mod, target_machine)

    # Look up the function pointer (a Python int)
    func_ptr = engine.get_function_address("hello")

    # Turn into a Python callable using ctypes
    from ctypes import CFUNCTYPE, c_int
    hello = CFUNCTYPE(c_int)(func_ptr)

    res = hello()
    print('hello() returned', res)

# Run it!
run_jit(mod)
----

If you run this, you should see the program run the code, and
produce output such as this:

----
bash % python3 hellollvm.py
hello() returned 37
bash %
----

This version runs entirely inside an active Python interpreter process. 
If you can't get clang to work, you can always use this as a fallback.

==== Local Variables and Math Operations

To do more with LLVM, you need to use more instructions on the
`builder` object in the example.   To declare a local variable "x",
you use this method:

----
x = builder.alloca(int_type, name="x")
----

To load and store values, you use these instructions:

----
r = builder.load(x)        # Load a value from x into r
builder.store(r, x)        # Store r into y
----

To perform arithmetic, you use instructions such as these:

----  
r3 = builder.add(r1, r2)   # r3 = r1 + r2
r3 = builder.mul(r1, r2)   # r3 = r1 + r2
----

Here is an example that implements the program given at the start
of this exercise:

----
# hellollvm.py
from llvmlite.ir import (
    Module, Function, FunctionType, IntType, 
    Constant, IRBuilder
    )

mod = Module('hello')
int_type = IntType(32)

hello_func = Function(mod, FunctionType(int_type, []), name='hello')
block = hello_func.append_basic_block('entry')
builder = IRBuilder(block)

x = builder.alloca(int_type, name='x')
y = builder.alloca(int_type, name='y')
builder.store(Constant(int_type, 4), x)
builder.store(Constant(int_type, 5), y)
r1 = builder.load(x)
r2 = builder.mul(r1, r1)
r3 = builder.load(y)
r4 = builder.mul(r3, r3)
r5 = builder.add(r2, r4)
d = builder.alloca(int_type, name='d')
builder.store(r5, d)
builder.ret(builder.load(d))

print(mod)
----

An important thing about LLVM is that it is NOT a stack machine. It is based
on registers and Single Static Assignment (SSA).  Basically, every operation
produces a new variable that can only be assigned once.  It also requires explicit
load/store instructions to go between local variables and registers.  In the 
above example, you can't do an instruction such as `builder.add(x, y)` between
local variables.  You have to load the variables into registers first and
perform the instruction on the registers.

Try compiling the above program and running you code again:

----
bash % python3 hellollvm.py > hello.ll
bash % clang main.c hello.ll
bash % ./a.out
hello() returned 41
bash %
----

==== Functions with Arguments

Let's make a more interesting function.  This function takes two
arguments `x` and `y` and computes the value `x**2 + y**2`.  To
do this, we're going to follow similar steps as above. First, declare
the function, add a basic block, and make a new builder.  Once the
builder is obtained, we'll create some instructions to compute and
return the result. Add the following code to your `hellollvm.py`
program:

----
# hellollvm.py
...

# A user-defined function
from llvmlite.ir import DoubleType

ty_double = DoubleType()
dsquared_func = Function(mod, 
                         FunctionType(ty_double, [ty_double, ty_double]), 
                         name='dsquared')
block = dsquared_func.append_basic_block('entry')
builder = IRBuilder(block)

# Get the function args
x, y = dsquared_func.args

# Compute temporary values for x*x and y*y
xsquared = builder.fmul(x, x)
ysquared = builder.fmul(y, y)

# Sum the values and return the result
d2 = builder.fadd(xsquared, ysquared)
builder.ret(d2)

# Output the final module
print(mod)
----

One thing to notice is that you use the builder to carry out the steps
needed to perform the calculation that you're trying to perform. Python
variables such as `x`, `xsquared`, and `d2` are being used to
hold intermediate results.

If you run this program, you should output similar to the following:

----
; ModuleID = "hello"
...

define double @"dsquared"(double %".1", double %".2") 
{
entry:
  %".4" = fmul double %".1", %".1"
  %".5" = fmul double %".2", %".2"
  %".6" = fadd double %".4", %".5"
  ret double %".6"
}
----

To test it, modify the C bootstrap code as follows:

----
/* main.c */
#include <stdio.h>

extern int hello();
extern double dsquared(double, double);

int main() {
  printf("Hello returned: %i\n", hello());
  printf("dsquared(3, 4) = %f\n", dsquared(3.0, 4.0));
}
----

Compile as follows:

----  
bash % python3 hellollvm.py > hello.ll
bash % clang main.c hello.ll
bash % ./a.out
Hello returned: 41
dsquared(3, 4) = 25.000000
bash %
----

==== Calling an external function

Even though you're emitting low-level assembly code, there's no need
to completely reinvent the wheel from scratch.  One problem concerns
printing.  In our IR code, there is an instruction to print a value
to the screen.  How do you do that in LLVM?  The short answer is that
you don't (well, unless you're some kind of masochist).  You do printing
in C.  Make a new file `runtime.c` and put a
a `_print_int()` function in it like this:

----
/* runtime.c */
#include <stdio.h>

void _print_int(int x) {
    printf("out: %i\n", x);
}
----

Now, suppose you wanted to call that function from LLVM.  To do it,
you need to declare it:

----
# hellollvm.py
...
from llvmlite.ir import VoidType, IntType

void_type = VoidType()
int_type = IntType(32)

_print_int = Function(mod, 
                     FunctionType(void_type, [int_type]), 
                     name='_print_int')
----

To call the function, you use the `builder.call()` instruction:

----
r2 = builder.call(_print_int, [r1])
----

Change your `hellollvm.py` program so that it looks like this:

----
# hellollvm.py

from llvmlite.ir import (
    Module, Function, FunctionType, IntType, VoidType,
    Constant, IRBuilder
    )

mod = Module('hello')

int_type = IntType(32)
void_type = VoidType()

_print_int = Function(mod, 
                      FunctionType(void_type, [int_type]), 
                      name='_print_int')

hello_func = Function(mod, FunctionType(int_type, []), name='hello')
block = hello_func.append_basic_block('entry')
builder = IRBuilder(block)

x = builder.alloca(int_type, name='x')
y = builder.alloca(int_type, name='y')
builder.store(Constant(int_type, 4), x)
builder.store(Constant(int_type, 5), y)
t1 = builder.load(x)
t2 = builder.load(x)
t3 = builder.mul(t1, t2)
t4 = builder.load(y)
t5 = builder.load(y)
t6 = builder.mul(t4, t5)
t7 = builder.add(t3, t6)
d = builder.alloca(int_type, name='d')
builder.store(t7, d)
builder.call(_print_int, [builder.load(d)])     # Call _print_int()
builder.ret(Constant(int_type, 37))             # Return 37
print(mod)
----

Compile and run (note inclusion of `runtime.c`):

----
bash % python3 hellollvm.py > hello.ll
bash % clang main.c runtime.c hello.ll
bash % ./a.out
out: 41
hello() returned 41
bash %
----

Notice that there is output from the `_print_int()` function as well as
the return value from the `hello()` function itself.  

As an aside, you can implement almost anything that you want in C and
link it as library code into your output assembly code.  Printing,
memory access, and all sorts of other things could potentially be
written in this way.  You'll have to do some of this in the project.

==== Global Variables and State

You might want to define a variable that keeps its state.  Let's make
a global variable `x`:

----
# hellollvm.py
...
from llvmlite.ir import GlobalVariable
x_var = GlobalVariable(mod, ty_double, 'x')
x_var.initializer = Constant(ty_double, 0.0)
----

Now, let's write a function that increments the variable and 
prints its new value.  To do this, you use `load` and `store`
instructions to manipulate the variable state:

----
# hellollvm.py
...

from llvmlite.ir import VoidType

incr_func = Function(mod, 
                     FunctionType(VoidType(), []), 
                     name='incr')
block = incr_func.append_basic_block('entry')
builder = IRBuilder(block)
tmp1 = builder.load(x_var)
tmp2 = builder.fadd(tmp1, Constant(ty_double, 1.0))
builder.store(tmp2, x_var)
builder.ret_void()
----

Modify the `main.c` file as follows:

----
/* main.c */
#include <stdio.h>

extern int hello();
extern double dsquared(double, double);
extern double x;
extern void incr();

int main() {
  printf("Hello returned: %i\n", hello());
  printf("dsquared(3, 4) = %f\n", dsquared(3.0, 4.0));
  printf("x is %f\n", x);
  incr();
  printf("x is now %f\n", x);
}
----

Compile and run the program again::

----
bash % python3 hellollvm.py > hello.ll
bash % clang main.c hello.ll -lm
bash % ./a.out
out: 41
Hello returned: 41
dsquared(3, 4) = 25.000000
x is 0.000000
x is now 1.000000
bash %
----

==== Compiling to LLVM

In building your compiler, you'll need to figure out how to translate
IR code into the appropriate low-level LLVM operations.  This part
is left to the project, but the mechanics of it are going to be almost
identical to the interpreter/transpiler exercises you did earlier. 
You need to keep track of variables. You need a stack to keep track of
LLVM values. Most of the code generation will involve operations on this
stack.

==== A LLVM Mini-Reference

This section aims to provide a mini-reference for using LLVM in the
next part of the project.   It summarizes some of the critical bits.

For creating LLVM code, use the following import:

----
from llvmlite.ir import (
     Module, Function, FunctionType, IRBuilder, 
     IntType, DoubleType, VoidType, Constant
)
----

All LLVM code is placed in a module.  You create one like this:

----
mod = Module("modname")
----

You declare functions like this:

----
func = Function(mod, 
                FunctionType(rettype, [argtypes]),
                name="funcname")
----

The following basic datatypes are used heavily in declarations:

---- 
IntType(32)             # A 32-bit integer
DoubleType()            # A double-precision float
----

It is usually easier to make aliases for the types:

----
int_type = IntType(32)
float_type = DoubleType()
----

To define constants corresponding to the above types, do this:

----  
c = Constant(int_type, value)
d = Constant(float_type, value)
----

To start adding code to a function, you must add a basic block
and create a builder.  For example:

----
block = func.append_basic_block('entry')
builder = IRBuilder(block)
----

Builder objects have a variety of useful methods for adding
instructions.  These include:

----
# Returning values
builder.ret(value)            
builder.ret_void()            

# Integer math
result = builder.add(left, right)
result = builder.sub(left, right)
result = builder.mul(left, right)
result = builder.sdiv(left, right)    

# Floating math
result = builder.fadd(left, right)
result = builder.fsub(left, right)
result = builder.fmul(left, right)
result = builder.fdiv(left, right)

# Function call
result = builder.call(func, args)
----

When using the builder, it is important to emphasize that you must
save the results of the above operations and use them in subsequent
calls.  For example:

----
t1 = builder.fmul(a, b)
t2 = builder.fmul(c, d)
t3 = builder.fadd(t1, t2)
...
----

To declare a local variable do something like this:

----
name_var = builder.alloca(int_type, name='varname')
----

To declare a global variabel do something like this:

----
x_var = GlobalVariable(mod, ty_double, 'x')
x_var.initializer = Constant(ty_double, 0.0)
----

To access either kind of variable, use load and store instructions:

----
tmp = builder.load(name_var)
builder.store(tmp, name_var)
----

=== Part (d) - Taking it to the Web (Assembly)

As our final target, we're going to compile our code to Web Assembly
(Wasm).  Wasm is a relatively new technology that is usually
introduced with a fairly complicated toolchain.  For example, it is
possible to compile C, C++, Rust, and other languages to Wasm and to
have that code run (somehow) in the browser.  You can even find demos
of game engines and other interesting things.  However, it can be a
bit tough to wrap your brain around what's happening.  In this last
part, we're going to look at raw low-level Wasm without any assistive
tooling.  This is not the way that you'd likely work with it for real,
but for the purposes of a compilers course, it's instructive.

At a high-level, Wasm is a small "machine code" that is not too unlike
the IR Code for our compiler.  It simulates a stack machine and it
only understands 4 datatypes--integers and floats in both 32-bit and
64-bit encodings.  The main difference is that Wasm is encoded in a
compact binary encoding---not a list of tuples as we have done.
Much of our effort to make Wasm work concerns details of the binary
encoding.

As a note: To make it somewhat simpler to describe, our encoding will not be
as compact as it could be.  Web Assembly uses a number of techniques
to compress the size of the output file at the expense of added encoding
complexity.  For the purpose of a course, it's probably better to optimize
for simplicity instead.

==== Low-level Encoding of Values

To start out, there are some basic encodings of integers, floats, and
text strings that need to take place.

Integers are encoded into a LEB-128, a variable length encoding. The
following functions can be used for this purpose:

----
def encode_unsigned(value):
    '''
    Produce an LEB128 encoded unsigned integer.
    '''
    parts = []
    while value:
        parts.append((value & 0x7f) | 0x80)
        value >>= 7
    if not parts:
        parts.append(0)
    parts[-1] &= 0x7f
    return bytes(parts)

def encode_signed(value):
    '''
    Produce a LEB128 encoded signed integer.
    '''
    parts = [ ]
    if value < 0:
        # Sign extend the value up to a multiple of 7 bits
        value = (1 << (value.bit_length() + (7 - value.bit_length() % 7))) + value
        negative = True
    else:
        negative = False
    while value:
        parts.append((value & 0x7f) | 0x80)
        value >>= 7
    if not parts or (not negative and parts[-1] & 0x40):
        parts.append(0)
    parts[-1] &= 0x7f
    return bytes(parts)

assert encode_unsigned(624485) == bytes([0xe5, 0x8e, 0x26])
assert encode_unsigned(127) == bytes([0x7f])
assert encode_signed(-624485) == bytes([0x9b, 0xf1, 0x59])
assert encode_signed(127) == bytes([0xff, 0x00])
----

Floating point numbers are encoded directly as a little-endian 8-byte double precision
value using this function:

----
def encode_f64(value):
    '''
    Encode a 64-bit float point as little endian
    '''
    return struct.pack('<d', value)
----

Wasm sometimes involves the encoding of a so-called "vector".  A vector is
list of identically typed items. For example, you could have a vector of 
integers, a vector of floats, a vector of bytes, and so forth.  Vectors are
encoded as an unsigned length followed by the raw encoding of whatever items
it contains.  So, write the following function:

----
def encode_vector(items):
    '''
    A size-prefixed collection of objects.  If items is already
    bytes, it is prepended by a length and returned.  If items
    is a list of byte-strings, the length of the list is prepended
    to byte-string formed by concatenating all of the items.
    '''
    if isinstance(items, bytes):
        return encode_unsigned(len(items)) + items
    else:
        return encode_unsigned(len(items)) + b''.join(items)
----

Names are represented as a UTF-8 encoded vector of bytes.  The following
function will encoded a name:

----
def encode_name(name):
    '''
    Encode a text name as a UTF-8 vector
    '''
    return encode_vector(name.encode('utf-8'))
----

The first rule of Wasm is that ALL literal values (integers, floats, names, etc.) must
be encoded by these functions. So, put these in a file `wasm.py` and use it as a starting
point.

Try a few examples to see what the encodings look like:

----
>>> encode_unsigned(1234)
b'\xd2\t'
>>> encode_signed(-1234)
b'\xaev'
>>> encode_f64(123.45)
b'\xcd\xcc\xcc\xcc\xcc\xdc^@'
>>> encode_name('spam')
b'\x04spam'
>>> 
----

Reminder: You must use these functions.

==== Some Basic Instructions

Wasm defines a set of instructions similar to our own IR code.  Wasm
is also a stack machine just like our IR code. The following table 
shows a few basic instruction encodings:

----
b'\x41' <val>  => i32.const (val is signed integer)
b'\x6a'        => i32.add
b'\x6b'        => i32.sub
b'\x6c'        => i32.mul
b'\x6d'        => i32.div_s
b'\x0b'        => end block
----

Using this, we can start to write a basic Wasm instruction encoder for our example
code. This is surprising easy---since Wasm is also a stack machine, we
don't need to maintain a stack or do much of anything other than translate
the tuples of IR code into the binary coded version in Wasm:

----
class WasmEncoder:
    def encode(self, code):
        self.wcode = b''
        for op, *opargs in code:
            getattr(self, f'encode_{op}')(*opargs)

        # Put a block terminator on the code
        self.wcode += b'\x0b'

    def encode_CONSTI(self, value):
        self.wcode += b'\x41' + encode_signed(value)

    def encode_ADDI(self):
        self.wcode += b'\x6a'

    def encode_MULI(self):
        self.wcode += b'\x6c'

    def encode_PRINTI(self):
        # TO-DO
        pass

    def encode_GLOBALI(self, name):
        # TO-DO
        pass

    def encode_STORE(self, name):
        # TO-DO
        pass

    def encode_LOAD(self, name):
        # TO-DO
        pass


encoder = WasmEncoder()
encoder.encode(code)
print(encoder.wcode)
----

Try running this example. You should get some low-level output that looks like this:

----
bash % python3 wasm.py
b'A\x04A\x05llj\x0b'
bash %
----

The output is binary and not meant to be easily human readable.

==== Types and Global Variables

The low-level instruction stream you just generated is incomplete. Instructions
related to global variables were left unimplemented.  To do this, a bit
more information is needed.

Wasm only has a four datatypes. Instead of being referenced by nice names
like "int" or "float", they are identified by specific byte values:

----
i32 = b'\x7f'   # (32-bit int)
i64 = b'\x7e'   # (64-bit int)
f32 = b'\x7d'   # (32-bit float)
f64 = b'\x7c'   # (64-bit float)
----

Put the above definitions in your encoder.  Instead of using a raw byte
value like `b'\x7f'`, you'll use the name `i32`.

A global variable in Wasm consists of a type, a mutability flag, and a
constant initial value.  All of the variables are stored in a table
which you can represent as a Python list.  Here is an example:

----
global_defns = [
    i32 + b'\x01\x41' + encode_signed(initial) + b'\x0b',  # integer	    
    f64 + b'\x01\x44' + encode_f64(initial) + b'\x0b',     # float
    ...
]
----

To load/store global variables, a pair of instructions are used:

----
b'\x23' <globidx>  => global.get
b'\x24' <globidx>  => global.set
----

The `global.get` instruction loads a variable from a global and puts it on
the stack.  The `global.set` instruction stores the top of the stack into
a variable.  The `globidx` value is an unsigned integer index into the
globals table.   To associate this with a variable name, you'll need to
maintain a separate dictionary:

----
# Mapping of variable names to global variable table indices
globals = {
   'x':   0,
   'y':   1,
   ...
}
----

Putting all of this together, here is how global variables get 
added to your encoder:

----
class WasmEncoder:
    def __init__(self):
        # Global variable table
        self.global_defns = [ ]

        # Table mapping global names to definition index
        self.globals = { } 
    ...

    def encode_GLOBALI(self, name):
        self.globals[name] = len(self.global_defns)
        self.global_defns.append(i32 + b'\x01\x41' + encode_signed(0) + b'\x0b')

    def encode_STORE(self, name):
        self.wcode += b'\x24' + encode_unsigned(self.globals[name])

    def encode_LOAD(self, name):
        self.wcode += b'\x23' + encode_unsigned(self.globals[name])
----

Add these to your encoder and look at the resulting output.  It 
should look something like this:

----
bash % python3 wasm.py
b'A\x04$\x00A\x05$\x01#\x00#\x00l#\x01#\x01lj$\x02#\x02\x0b'
bash %
----

==== Function Encoding

The low-level instruction stream you just generated is not enough to
make Wasm work.  Wasm requires all code to be packaged up inside a
proper function.  To do this, you need to deconstruct function definitions
into parts. Consider the following Wabbit function:

----
func spam(x int, y int) int {
    var z int;
    z = x + y;
    return z;
}
----

The function consists of three different parts.  There is a textual
name `'spam'`, a type signature `(int, int)->int`, and a function
body that contains the function code.   In Wasm, these three components
are stored in separate tables.

In Wasm, a function type signature is expressed as a pair of tuples
containing the parameter and return types. For example, the signature
for `spam()` above is:

----
[(i32, i32), (i32,)]
----

or if you fill in the raw type-codes:

----
[(b'\x7f', b'\x7f'), (b'\x7f',)]
----

To encode a signature into bytes, use the following function:

----
def encode_signature(argtypes, rettypes):
    return b'\x60' + encode_vector(argtypes) + encode_vector(rettypes)
----

Type signatures for all functions are stored in a list.  For example,
suppose you had the following functions in your Wasm file:

----
func spam(x int, y int) int;
func square(x float) float;
func blah(x float, y int) float;
----

You will make a type-signature list like this:

----
signatures = [
   encode_signature([i32, i32], [i32]),    # spam
   encode_signature([f64], [f64]),         # square
   encode_signature([f64, i32], [f64]),    # blah
]
----

Carefully notice that the signature table contains no information
about function names.  For that, you need to maintain a separate
dictionary that maps names to an associated type index.  For example:

----
functions = {
   'spam': 0,       # Index refers to type signature table
   'square': 1,
   'blah': 2,
}
----

The code associated with each function is also stored in a table.

----
funccode = [
    b'...',        # Code for spam
    b'...',        # Code for square
    b'...',        # Code for blah
]
----

The code stored here is the same code that you've been making so far.
However, some additional considerations must be made to handle local
variables. Consider the following function again:

----
func spam(x int, y int) int {
    var z int;
    z = x + y;
    return z;
}
----

This function has two parameters (`x`, `y`) and a local variable `z`.
These variables are numbered starting at 0 (parameters go first).  You
need to make a dict that maps variable names to numerical indices:

----
locals = {
    'x': 0,
    'y': 1,
    'z': 2,
}
----

The following Wasm instructions are used to load/store local variables:

----
b'\x20' <localidx>  => local.get
b'\x21' <localidx>  => local.set
----

Here, `localidx` is an unsigned integer index that refers to the
variable (the same index that's stored in the `locals` variable above).

The types of the function parameters are stored as part of the
signature.  However, the types of additional local variables (declared
inside the function) must be stored in a separate list.  So, you need
to keep a separate record like this:

----
localtypes = [ b'\x01' + i32 ]     # Type of z
----

It looks a little funny, but each local variable type is encoded with 
`b'\x01'+<typecode>`.    The contents of this list are encoded as a
vector and prepended to the raw instruction code that you already 
created.    The entire function body (locals + code) is then prepended
by an integer length giving its size in bytes.  Structurally, it's going
to look like this:

----
[ length | locals | instructions ]
----

Last, but not least, you need to export your newly created function
so that it can be accessed.  To do that, you make an exports list like this:

----
exports = []

# An a function "name" to the exports list
exports.append(encode_name(name) + b'\x00' + encode_unsigned(functions[name]))
----

This is a lot to unpack, but here is a modified encoder that includes
the necessary function support:

----
def encode_signature(argtypes, rettypes):
    return b'\x60' + encode_vector(argtypes) + encode_vector(rettypes)

class WasmEncoder:
    def __init__(self):
        # Global variables
        self.global_defns = [ ]

        # Global variable symbol table mapping names to declarations
        self.globals = { } 

        # Function type signatures
        self.signatures = [ ]

        # Function name -> signature map
        self.functions = { }

        # Function bodies
        self.funccode = [ ]

        # Exported functions
        self.exports = [ ]

    def encode_function(self, name, parmnames, parmtypes, rettypes, code):
        self.functions[name] = len(self.signatures)
        self.signatures.append(encode_signature(parmtypes, rettypes))
        self.exports.append(encode_name(name) + b'\x00' + encode_unsigned(self.functions[name]))

        # Create the local variable mapping
        self.locals = { pname: n for n, pname in enumerate(parmnames) }
        self.localtypes = [ ]

        # Emit instructions
        self.wcode = b''
        for op, *opargs in code:
            getattr(self, f'encode_{op}')(*opargs)

        # Put a block terminator on the code
        self.wcode += b'\x0b'

        # Save the function code body
        code = encode_vector(self.localtypes) + self.wcode
        self.funccode.append(encode_unsigned(len(code)) + code)

    ... rest unchanged ...

# Example use
encoder = WasmEncoder()
encoder.encode_function("main", [], [], [i32], code)
----

If you run this code and inspect various attributes of the encoder, you
should see the following:

----
>>> encoder.signatures
[b'`\x00\x01\x7f']
>>> encoder.functions
{'main': 0}
>>> encoder.funccode
[b'\x19\x00A\x04$\x00A\x05$\x01#\x00#\x00l#\x01#\x01lj$\x02#\x02\x0b']
>>> encoder.exports
[b'\x04main\x00\x00']
>>> 
----

We're almost at a point where you can make something run.  The last step is to
make a proper Wasm module.

==== Encoding a Module

Your final step in encoding Wasm is to make an encoded module. A module
is broken up into sections and looks like this:

----

                +----------------------------+
 Header    :    | b'\x00asm\x01\x00\x00\x00' |
                +----------------------------+
 Section 1 :    |    type signatures         |
                +----------------------------+    
 Section 3 :    |    function types          |
                +----------------------------+    
 Section 6 :    |    globals                 |
                +----------------------------+    
 Section 7 :    |    exports                 |
                +----------------------------+          
 Section 10 :   |    function code           |
                +----------------------------+          
----

There are other optional sections that are not needed right now.  The encoding
of each section is a 1-byte section number, a section length, and section contents.
Write the following functions:

----
def encode_section(sectnum, contents):
    return bytes([sectnum]) + encode_unsigned(len(contents)) + contents
----

The contents of each section is encoded as a vector. So, to encode
section 1 for instance, you would do this:

----
encode_section(1, encode_vector(signatures))
----

Put all of this together by adding an `encode_module()` method like
this:

----
class WasmEncoder:
    ...
    def encode_module(self):
        module = b'\x00asm\x01\x00\x00\x00'
        module += encode_section(1, encode_vector(self.signatures))
        vec = [encode_unsigned(v) for v in self.functions.values()]
        module += encode_section(3, encode_vector(vec))
        module += encode_section(6, encode_vector(self.global_defns))
        module += encode_section(7, encode_vector(self.exports))
        module += encode_section(10, encode_vector(self.funccode))
        return module

# Example use:
encoder = WasmEncoder()
encoder.encode_function("main", [], [], [i32], code)
with open('out.wasm', 'wb') as file:
    file.write(encoder.encode_module())
----

Put this in your file and run it.  You should get a file `out.wasm`
written in the current directory.

==== Loading it in the Browser

Wasm doesn't run by itself.  It needs to be launched from Javascript.
Create a file `hello.html` that contains the following HTML and
Javascript:

----
<html>
<body>
<h3>Program Output</h3>

<pre id="myout">The output is: </pre>

<script>
    var imports = { };
    fetch("out.wasm").then(response =>
       response.arrayBuffer()
    ).then(bytes =>
       WebAssembly.instantiate(bytes, imports)
    ).then(results => {
       window.main = results.instance.exports.main;
       out = window.main();
       document.getElementById("myout").innerHTML += out + "\n";
    });
</script>
</body>
</html>
----

In this code, the `out.wasm` file is fetched and instantiated into a WebAssembly
instance.  The `main()` function is lifted out of the instance exports
section. When called, its output is appended to the HTML in the `<pre>` 
section at the top.  

To test this, go to the command line and the same directory as the `hello.html`
and `out.wasm` file.  Run the following Python command:

----
bash % python3 -m http.server
----

This launches a web server.  Now click on
http://localhost:8000/hello.html.  You should see an output of "41".
If you see nothing, open the JavaScript dev console in your browser,
reload, and look for error messages.  Even the slightest error in
encoding your module will cause it to fail. Ask for help if stuck.

==== Building the Runtime

Wasm is extremely low-level and minimal.  Keep in mind you only get integers and floats.
There are no strings. Or even any built-in functions!  Wasm doesn't get access to
any part of Javascript or the browser environment all by itself.  This 
presents certain logistical problems.  For example, how do you implement the
`PRINTI` instruction?  

The solution here is the same as the solution in LLVM!  If you want printing,
you implement it in JavaScript, not Wasm.   Go to the `hello.html` file and
modify the code so it looks like this:

----
<html>
<body>
<h3>Program Output</h3>

<pre id="myout">The output is: </pre>

<script>
    var imports = { 
       runtime : {
           _printi: (x) => { document.getElementById("myout").innerHTML += x + "\n"; },
       }	   
     };
    fetch("out.wasm").then(response =>
       response.arrayBuffer()
    ).then(bytes =>
       WebAssembly.instantiate(bytes, imports)
    ).then(results => {
       window.main = results.instance.exports.main;
       window.main();
    });
</script>
</body>
</html>
----

Carefully observe that we have added a `_printi()` function to the
`imports` variable.  The original output at the end has been
removed.

To make the `_printi` function available to Wasm, it has to be explicitly
imported.  This is done by making import records and making a few minor
modifications as shown in this extension to the encoder:

----
class WasmEncoder:
    def __init__(self):
        ...
        # Imported functions
        self.imports = [ ]

    def import_function(self, module, name, parmtypes, rettypes):
        assert not self.exports, "All imported functions must be declared first"
        self.functions[name] = len(self.signatures)
        self.signatures.append(encode_signature(parmtypes, rettypes))
        self.imports.append(encode_name(module)+encode_name(name)+b'\x00' + 
	                    encode_unsigned(self.functions[name]))

    ...

    def encode_module(self):
        module = b'\x00asm\x01\x00\x00\x00'
        module += encode_section(1, encode_vector(self.signatures))

	# --- Next two lines added/modified. Don't forget slice on 2nd line!
        module += encode_section(2, encode_vector(self.imports))   
        vec = [encode_unsigned(v) for v in self.functions.values()][len(self.imports):]
        # ---

        module += encode_section(3, encode_vector(vec))
        module += encode_section(6, encode_vector(self.global_defns))
        module += encode_section(7, encode_vector(self.exports))
        module += encode_section(10, encode_vector(self.funccode))
        return module

    ...

    # Call the imported '_printi' function
    def encode_PRINTI(self):
        self.wcode += b'\x10' + encode_unsigned(self.functions['_printi'])

----

To use this new encoder, you need to declare the imported runtime function
and fiddle a bit with type signatures.  Do this:

----
encoder = WasmEncoder()

# Declare the runtime function
encoder.import_function("runtime", "_printi", [i32], [])

# Encode main(). Note: Return type changed to [].
encoder.encode_function("main", [], [], [], code)

# Write out the module
with open('out.wasm', 'wb') as file:
    file.write(encoder.encode_module())
----

Try running your code to produce another `out.wasm` file and reload the hello page
in the browser.  You should see output being produced as before. If not, you'll
have to do some debugging.  Whew!  That was some work.

==== A Wasm Mini Reference

This section provides a short reference of useful Wasm instructions
and data encoding

Types:

---- 
b'\x7f'     => i32
b'\x7c'     => f64
----

It is usually easier to make aliases for the types:

----
i32 = b'\x7f'
f64 = b'\x7c'
----

To define constants corresponding to the above types, do this:

----  
b'\x41' <value>  => i32.const value
b'\x44' <value>  => f64.const value
----

The `<value>` needs to be encoded using `encoded_signed()` or `encode_f64()` depending
on the type.

Here are some useful opcodes for math:

----
b'\x6a'        => i32.add
b'\x6b'        => i32.sub
b'\x6c'        => i32.mul
b'\x6d'        => i32.div_s

b'\xa0'        => f64.add
b'\xa1'        => f64.sub
b'\xa2'        => f64.mul
b'\xa3'        => f64.div
----

To access a global variable, use these load and store instructions:

----
b'\x23' <globalidx>  => global.get
b'\x24' <globalidx>  => global.set
----


To access a local variable, use load and store instructions:

----
b'\x20' <localidx>  => local.get
b'\x21' <localidx>  => local.set
----

To call a function:

----
b'\x10' <funcidx>  => call  (funcidx is function index)
----

More instructions can be found in the Wasm official specification.

==== Complete Encoder

Here is the source code for the complete encoder developed
in this part:

----
code = [
   ('GLOBALI', 'x'),
   ('CONSTI', 4),
   ('STORE', 'x'),
   ('GLOBALI', 'y'),
   ('CONSTI', 5),
   ('STORE', 'y'),
   ('GLOBALI', 'd'),
   ('LOAD', 'x'),
   ('LOAD', 'x'),
   ('MULI',),
   ('LOAD', 'y'),
   ('LOAD', 'y'),
   ('MULI',),
   ('ADDI',),
   ('STORE', 'd'),
   ('LOAD', 'd'),
   ('PRINTI',)
]

def encode_unsigned(value):
    '''
    Produce an LEB128 encoded unsigned integer.
    '''
    parts = []
    while value:
        parts.append((value & 0x7f) | 0x80)
        value >>= 7
    if not parts:
        parts.append(0)
    parts[-1] &= 0x7f
    return bytes(parts)

def encode_signed(value):
    '''
    Produce a LEB128 encoded signed integer.
    '''
    parts = [ ]
    if value < 0:
        # Sign extend the value up to a multiple of 7 bits
        value = (1 << (value.bit_length() + (7 - value.bit_length() % 7))) + value
        negative = True
    else:
        negative = False
    while value:
        parts.append((value & 0x7f) | 0x80)
        value >>= 7
    if not parts or (not negative and parts[-1] & 0x40):
        parts.append(0)
    parts[-1] &= 0x7f
    return bytes(parts)

assert encode_unsigned(624485) == bytes([0xe5, 0x8e, 0x26])
assert encode_unsigned(127) == bytes([0x7f])
assert encode_signed(-624485) == bytes([0x9b, 0xf1, 0x59])
assert encode_signed(127) == bytes([0xff, 0x00])

def encode_vector(items):
    '''
    A size-prefixed collection of objects.  If items is already
    bytes, it is prepended by a length and returned.  If items
    is a list of byte-strings, the length of the list is prepended
    to byte-string formed by concatenating all of the items.
    '''
    if isinstance(items, bytes):
        return encode_unsigned(len(items)) + items
    else:
        return encode_unsigned(len(items)) + b''.join(items)

import struct
def encode_f64(value):
    '''
    Encode a 64-bit float point as little endian
    '''
    return struct.pack('<d', value)

def encode_name(name):
    '''
    Encode a text name as a UTF-8 vector
    '''
    return encode_vector(name.encode('utf-8'))

def encode_signature(argtypes, rettypes):
    return b'\x60' + encode_vector(argtypes) + encode_vector(rettypes)

def encode_section(sectnum, contents):
    return bytes([sectnum]) + encode_unsigned(len(contents)) + contents

i32 = b'\x7f'
f64 = b'\x7d'

class WasmEncoder:
    def __init__(self):
        # Global variables
        self.global_defns = [ ]

        # Global variable symbol table mapping names to declarations
        self.globals = { } 

        # Function type signatures
        self.signatures = [ ]

        # Function name -> signature map
        self.functions = { }

        # Function bodies
        self.funccode = [ ]

        # Exported functions
        self.exports = [ ]

        # Imported functions
        self.imports = [ ]

    def import_function(self, module, name, parmtypes, rettypes):
        assert not self.exports, "All imported functions must be declared first"
        self.functions[name] = len(self.signatures)
        self.signatures.append(encode_signature(parmtypes, rettypes))
        self.imports.append(encode_name(module)+encode_name(name)+b'\x00' + encode_unsigned(self.functions[name]))

    def encode_function(self, name, parmnames, parmtypes, rettypes, code):
        self.functions[name] = len(self.signatures)
        self.signatures.append(encode_signature(parmtypes, rettypes))
        self.exports.append(encode_name(name) + b'\x00' + encode_unsigned(self.functions[name]))

        # Create the local variable mapping
        self.locals = { pname: n for n, pname in enumerate(parmnames) }
        self.localtypes = [ ]

        # Emit instructions
        self.wcode = b''
        for op, *opargs in code:
            getattr(self, f'encode_{op}')(*opargs)

        # Put a block terminator on the code
        self.wcode += b'\x0b'

        # Save the function code body
        code = encode_vector(self.localtypes) + self.wcode
        self.funccode.append(encode_unsigned(len(code)) + code)

    def encode_module(self):
        module = b'\x00asm\x01\x00\x00\x00'
        module += encode_section(1, encode_vector(self.signatures))
        module += encode_section(2, encode_vector(self.imports))
        vec = [encode_unsigned(v) for v in self.functions.values()][len(self.imports):]
        module += encode_section(3, encode_vector(vec))
        module += encode_section(6, encode_vector(self.global_defns))
        module += encode_section(7, encode_vector(self.exports))
        module += encode_section(10, encode_vector(self.funccode))
        return module

    def encode_CONSTI(self, value):
        self.wcode += b'\x41' + encode_signed(value)

    def encode_ADDI(self):
        self.wcode += b'\x6a'

    def encode_MULI(self):
        self.wcode += b'\x6c'

    def encode_PRINTI(self):
        self.wcode += b'\x10' + encode_unsigned(self.functions['_printi'])

    def encode_GLOBALI(self, name):
        self.globals[name] = len(self.global_defns)
        self.global_defns.append(i32 + b'\x01\x41' + encode_signed(0) + b'\x0b')

    def encode_STORE(self, name):
        self.wcode += b'\x24' + encode_unsigned(self.globals[name])

    def encode_LOAD(self, name):
        self.wcode += b'\x23' + encode_unsigned(self.globals[name])


encoder = WasmEncoder()
encoder.import_function("runtime", "_printi", [i32], [])
encoder.encode_function("main", [], [], [], code)
with open('out.wasm', 'wb') as file:
    file.write(encoder.encode_module())
----





    
    
